---
title: "BIOS 617 - Lecture 7"
author: "Walter Dempsey"
date: "2/1/2023"
output:
  beamer_presentation: default
  ioslides_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Equal-size cluster sampling

* Often obtaining a sampling frame containing the individual units of interest may be difficult.
  + There are no listings of US adults; there are, however, listings of household addresses that are approximately complete (and can be made moreso by review, either “on foot” or, where possible, using Google Earth).
  + Similarly, it might be more convenient to list classes in a school rather
than students; nursing homes rather than patients; etc.
* For ease of exposition, we are going to assume for the moment
that
  + Once a cluster is sampled, all of the elements in that clusters are also
sampled (may or may not be practical or efficient).
  + All clusters are of equal size.
  + Clusters are sampled via SRS without replacement.

## Notation

* $i=1,\ldots, K$ clusters in the population
* $i=1,\ldots, k$ clusters in the sample
* $j=1,\ldots, M$ units in each cluster $(M \geq 2$)
* Total number of units in the population: $N=KM$
* Total number of units in the sample: $n=kM$
* $Y_{ij}$ is the observation associated with the $j$th unit in the $i$th cluster
* $\bar Y_i = M^{-1} \sum_j Y_{ij}$ is the mean of the $i$th cluster
* $\bar Y = K^{-1} \sum_i \bar Y_i = (KM)^{-1} \sum_{i=1}^K \sum_{j=1}^M Y_{ij}$


## Key equations

$$
S_k^2 = \frac{1}{K-1} \sum_{i=1}^K \left( \bar Y_i  - \bar Y \right)^2 = \frac{KM-1}{(K-1)M^2} S^2 \left[ 1 + (M-1) \rho \right]
$$

* Therefore

$$
\begin{aligned}
V(\bar y_c) &= \left( 1 - \frac{k}{K} \right) \frac{S_k^2}{k} \\
&=\left(1 - \frac{n}{N} \right) \frac{S^2}{n} \frac{KM-1}{KM-M} \left[ 1 + (M-1) \rho \right] \\
&\approx\left(1 - \frac{n}{N} \right) \frac{S^2}{n} \left[ 1 + (M-1) \rho \right] \\
&= V(\bar y_{SRS}) \left[ 1 + (M-1) \rho \right]
\end{aligned}
$$

## Design effects in equal-size cluster sampling

The deff for equal-size cluster sampling is given by

$$
deff = \frac{V(\bar y_c)}{ V(\bar y_{SRS})} \approx \frac{V(\bar y_{SRS})(1+(M-1)\rho)}{V(\bar y_{SRS})} = [1+(M-1)\rho]
$$

* $deff < 1$ when $\rho < 0$ (ex: gender in a household)
* $deff > 1$ when $\rho > 0$ (ex: race in a household)
* Minimized when $1+ (M-1) \rho = 0$ which is equivalent to $\rho = - \frac{1}{M-1}$
* Maximized when $\rho = 1$: $deff = M$


## NEW MATERIAL: Systematic sampling

* Before modern computing, drawing a simple random sample without replacement was a non-trivial task.
* Much easier would be to sample every $k$th element in a sampling frame, where $k = N/n = f^{-1}$ (assuming for the moment that $n$ is a factor of $N$).
* Even today, if frame is not in an electronic form, some type of systematic sampling might be required.
  + Even if not required, systematic sampling is often at least as efficient as SRS: implicit stratification in order of sampling frame.
  + Disadvantage is that unbiased estimator of variance cannot be obtained without making assumptions about the sampling frame.

## Systematic sampling

* Always starting at the first element means that only a single sample can be obtained from the population – no sampling variability.
* Choose a random start $r$ between $1$ and $k$: select elements $Y_r, Y_{r+k}, \ldots, Y_{r+(n-1)k}$
  + $k$ possible samples, all with equal probability of selection $1/k$

## Systematic sampling

* Combination of cluster and stratified sampling.
* Design effect is not estimable, since we are sampling only
one element.
  + Order of the list achieves stratification with respect to a given measure to the extent that the list is ordered according to that measure.
* Size of business, age of customer, etc.
* Stratified proportionate allocation.

## Expectation of $\bar y_{sys}$

The mean is unbiased:
$$
\bar y_{sys} = \sum_{i=1}^k I(i \in s) \bar y_i = \sum_{i=1}^k I(i \in s) \left[ \frac{1}{n} \sum_{j=1}^n Y_{i+(j-1)k}] \right]
$$
so
$$
E[\bar y_{sys}] = \sum_{i=1}^k E[I(i \in s)] \bar y_i = \sum_{i=1}^k \frac{1}{k} \left[ \frac{1}{n} \sum_{j=1}^n Y_{i+(j-1)k}] \right] = \bar Y.
$$

## Variance of $\bar y_{sys}$

Recall from previous work that the variance of a cluster sample
design with all elements in the cluster sampled is given by

$$
V(\bar y_c) = \left ( 1 - \frac{a}{A} \right) \frac{S^2}{aB} \frac{AB-1}{B(A-1)} \left[ 1 + (B-1) \rho \right]
$$
where, to avoid notation confusion, the total number of clusters in the population is A, the number of clusters sampled is a, the number of elements in each cluster is B, and the intraclass correlation is $\rho$.

## Variance of $\bar y_{sys}$

In systematic sampling, $a=1$, so, reverting to the notation of the systematic sampling slides, we have
$$
\begin{aligned}
V(\bar y_c) &= \left ( 1 - \frac{1}{k} \right) \frac{S^2}{n} \frac{nk-1}{n(k-1)} \left[ 1 + (n-1) \rho \right] \\
&=\frac{S^2}{n} \frac{nk-1}{nk} \left[ 1 + (n-1) \rho \right]
\end{aligned}
$$

* PROBLEM!
* With only a single cluster, we have no information to estimate $\rho$.
* Have to make some (modeling) assumptions.

## Assuming a random order

* If we assume that there is no within-cluster correlation, systematic sample is equivalent to SRS:
$$
\begin{aligned}
v(\bar y_{sys}) &= \frac{S^2}{n} \frac{nk-1}{nk} \\
&= \left( 1 - \frac{1}{k} \right) \frac{S^2}{n} \left( \frac{k}{k-1} \right) \left(  \frac{nk-1}{nk} \right) \\
&= V(\bar y_{srs} ) \left( \frac{k}{k-1} \right) \left(  \frac{nk-1}{nk} \right) \\
&= V(\bar y_{srs} ) \left(  \frac{nk-1}{n(k-1)} \right) \\
\end{aligned}
$$
So as $nk= N \to \infty$ for fixed $n$, $V(\bar y_{sys}) \to V(\bar y_{srs})$

## Assuming a stratified order: paired selections model

* Very often, the list is ordered in some fashion.
  + Date of birth (approx. random)
  + Alphabetical by last name (might be some stratification by ethnicity)
  + Categorization (NAICS codes for business)
  + Size measure: population of county, number of employees in a business
* Treat as one selection per stratum and collapse together using collapsed strata variance estimator:
* $y_1,y_2 \to y_{11}, y_{21}$ and so on
* Variance is $v(\bar y_{str}) = \frac{1-f}{n^2} \sum_{j=1}^{n/2} (y_{j1}-y_{j2})^2$

## Assuming a stratified order: paired selections model

$$
\begin{aligned}
E[ (\bar y_{j1} - \bar y_{j2})^2] &= E \left[  (\bar Y_{j1} - \bar Y_{j2})^2 +  (\bar y_{j1} - \bar Y_{j1})^2 +  (\bar Y_{j2} - \bar y_{j2})^2 \right] \\
&= (\bar Y_{j1} - \bar Y_{j2})^2 +  E \left [ (\bar y_{j1} - \bar Y_{j1})^2 \right] + E \left[ (\bar Y_{j2} - \bar y_{j2})^2 \right] \\
&= (\bar Y_{j1} - \bar Y_{j2})^2 +  \frac{N_{j1}-1}{N_{j1}} S_{j1}^2  + \frac{N_{j2}-1}{N_{j2}} S_{j2}^2\\
\end{aligned}
$$
So
$$
E[ v(\bar y_{sys})] = \frac{1-f}{n^2} \left( \sum_{j=1}^{n/2} \left( \bar Y_{j1} - \bar Y_{j2} \right)^2 + \sum_{h=1}^2 \frac{N_{jh} - 1}{N_{jh}} S_{jh}^2  \right)
$$

## Assuming a stratified order: successive differences model

* Now pair off successive elements: $\underbrace{(y_1, y_2), \ldots, (y_{n-1}, y_n)}_{n-1 \text{ pairs}}$
* Then 
$$
v(\bar y_{sys}) = \frac{1-f}{2 n (n-1)} \sum_{j=1}^{n-1} (y_j - y_{j+1})^2
$$
* For collapsed strata:
$$
\frac{1-f}{n^2} \sum_{j=1}^{n/2} \sum_{j=1}^{n/2} (y_{j1} - y_{j2})^2 = 
\frac{1-f}{2n} \left[ (n/2)^{-1} \sum_{j=1}^{n/2} \sum_{j=1}^{n/2} (y_{j1} - y_{j2})^2 \right] 
$$
* The final term is the mean of stratum variances
* If we replace with mean of the larger number of pairs then $n-1$ replaces $n/2$
  + Potentially more stable estimate.
  
## List periodicity

A practical issue of concern is _list periodicity_.

* Avoid sampling intervals that coincide with periodicity in the list.
  + Suppose there is a pairing of (heterosexual) spouses: HWHWHW. Even sampling interval will yield only men or only women, but an odd interval would work well.
  + Apartment block with 8 apartments per floor. Sampling interval of 8 gives same apartment on each floor, but an interval of 7 will work well.
  
## Non-integer intervals

* Our derivations have assumed that $N = kn$, that is $N/n$ is an integer.
* If $N/n$ is not an integer, then the sample size is random, equal to either $n$ or $n+1$, depending on the random start.
* Might ignore if $n$ is large, but there are methods to retain _epsem_ sampling for a fixed sample size $n$.

##  Option 1: Treat list as circular

* Rather than choose a random start $r$ in the interval $[1,k]$, choose random start across entire sampling frame
* Let $F = \left \lfloor \frac{N}{n} \right \rfloor$ and select observations $r+ Fj-l_j N$, $j=0,\ldots, n-1$ where $l_j = \left \lfloor \frac{r+Fj}{N} \right \rfloor$

##  Option 2

Use the correct fractional interval $F = N/n$ and round down: select observations $\left \lfloor \frac{r}{\lfloor F \rfloor + Fj} \right \rfloor$ for $j=0,\ldots,n-1$.

